# AI MUSIC WORKFLOW - TECHNICAL GUIDE

## Understanding workflow data and using technical files for quality control and troubleshooting

---

## FILE ORGANIZATION

After running the workflow, your results folder contains three subfolders:

### **`deliverables/`** - Working files for catalogers
- Sorting spreadsheet
- Batch upload file
- Review spreadsheets and text logs
- MARC format file

### **`guides/`** - Documentation
- Cataloger Guide
- Technical Guide (this document)

### **`data/`** - Workflow tracking files
- `full-workflow-data-[cd/lp]-[timestamp].json` - Master tracking file
- `full-workflow-data-[cd/lp]-[timestamp].xlsx` - Detailed Excel version
- `logs/` subfolder with processing details

---

## UNDERSTANDING THE MASTER WORKFLOW FILE

**Location**: `data/full-workflow-data-[cd/lp]-[timestamp].json`

This JSON file tracks every processing step for each barcode. It contains:
- Raw AI responses from metadata extraction
- OCLC API search queries and results
- AI analysis and reasoning for each match
- Confidence score calculations and adjustments
- Error logs and processing notes

### File Structure:
```json
{
  "records": {
    "barcode_12345": {
      "step1_metadata_extraction": {...},
      "step2_oclc_search": {...},
      "step3_ai_analysis": {...},
      "step4_verification": {...},
      "step5_final_classification": {...},
      "errors": [...]
    }
  },
  "batch_metadata": {...}
}
```

### When to use this file:
- **Auditing AI decisions** - Review why AI suggested a particular OCLC record
- **Understanding confidence scores** - See how scores were calculated and adjusted
- **Investigating errors** - Find details about what went wrong for specific items
- **Quality improvement** - Identify patterns in AI performance

---

## LOGS FOLDER CONTENTS

**Location**: `results-folder/logs/`

### Processing Logs:
- **`file_validation_log.txt`** - Step 0.5 file validation results
  - Lists valid and invalid image files
  - Shows naming convention issues

- **`step1_llm_response_log.txt`** - Full AI responses from metadata extraction
  - Shows what the AI "saw" in each image
  - Useful for understanding extraction errors

- **`step3_llm_response_log.txt`** - AI analysis of OCLC matches
  - Contains AI's reasoning for choosing each OCLC record
  - Shows confidence score justifications
  - Helpful for understanding why certain records were rated low

- **`oclc-api-search-log-[date].json`** - All OCLC API queries and results
  - Lists every search query attempted
  - Shows which searches succeeded/failed
  - Contains total number of holdings for each record

### Performance Logs:
- **`step1_token_usage_log.txt`** - Metadata extraction metrics
  - API token consumption
  - Estimated costs
  - Processing times

- **`step3_token_usage_log.txt`** - Analysis step metrics
  - Similar tracking for the analysis phase

- **`processing-metrics-[date].json`** - Structured performance data
  - Success/failure rates for each step
  - Processing times and bottlenecks
  - Confidence score distributions
  - OCLC API hit rates

### Error Tracking:
- **`error-log-[date].json`** - Comprehensive error log
  - All errors categorized by type
  - Timestamps and affected barcodes
  - Detailed error messages for troubleshooting

---

## QUALITY ASSURANCE STRATEGIES

### 1. Review Confidence Score Patterns

Check `processing-metrics-[date].json` for:
- Distribution of confidence scores (how many high vs. low)
- Average confidence by batch
- Records where confidence was reduced in Step 4

**Red flags**:
- Unusually high percentage of low-confidence matches
- Many scores reduced during verification step
- Systematic patterns in certain types of materials

### 2. Audit Low-Confidence Decisions

For low-confidence matches, review the workflow JSON:
1. Check `step1_metadata_extraction` - Was metadata extracted accurately?
2. Check `step2_oclc_search` - Were appropriate searches performed?
3. Check `step3_ai_analysis` - What was the AI's reasoning?
4. Check `step4_verification` - Why was confidence reduced?

### 3. Investigate OCLC Search Patterns

Use `oclc-api-search-log-[date].json` to identify:
- Searches that returned no results
- Searches that returned too many results (may need refinement)
- Common search terms that work well vs. poorly
- OCLC API errors or rate limiting issues

### 4. Analyze AI Extraction Quality

Review `step1_llm_responses_log.txt` for patterns:
- Fields consistently extracted incorrectly (e.g., dates, UPCs)
- Image quality issues affecting extraction
- Specific label designs that cause problems
- Text that AI consistently misreads

---

## COMMON ISSUES AND SOLUTIONS

### Issue: High percentage of low-confidence matches

**Investigation steps**:
1. Check `error-log-[date].json` for API errors or rate limiting
2. Review `step1_llm_responses_log.txt` - is metadata quality poor?
3. Look at `oclc-api-search-log-[date].json` - are searches finding records?
4. Review `step3_llm_responses_log.txt` - is AI being too conservative?

**Possible causes**:
- Poor image quality in batch
- Unusual or rare materials
- OCLC API issues
- Need for prompt refinement

### Issue: AI suggestions disagree with cataloger review

**Investigation steps**:
1. Review AI's reasoning in `step3_llm_responses_log.txt`
2. Check what OCLC records were available in step2 results
3. Look at confidence score calculation
4. Compare AI's analysis to actual record details

**Use this information for**:
- Documenting patterns for future workflow improvements
- Understanding AI limitations
- Training staff on when to trust vs. question AI suggestions

### Issue: Duplicates not properly detected

**Investigation steps**:
1. Check sorting spreadsheet - are duplicates marked?
2. Review workflow JSON for confidence scores of duplicate items
3. Look at OCLC numbers assigned - are they actually the same?

**Note**: Duplicate detection only runs on high-confidence matches (â‰¥80%)

### Issue: Items marked as "Held by IXA" but aren't actually in catalog

**Investigation steps**:
1. Check OCLC search log for holdings information
2. Verify the OCLC number in WorldCat
3. Check institutional holdings code in OCLC

**Note**: This relies on OCLC API holdings data being current

---

## USING DATA FOR WORKFLOW IMPROVEMENT

### Track AI Performance Over Time

Create a spreadsheet tracking:
- Batch date and size
- High confidence rate
- Low confidence rate
- Cataloger agreement rate (after review)
- Common error types

### Document Systematic Issues

When you notice patterns:
1. Note the material type (CD vs. LP, label, format)
2. Document the specific problem (extraction, search, matching)
3. Collect example barcodes and workflow JSON sections
4. Share with workflow administrators for prompt refinement


## REPROCESSING AND CORRECTIONS

### If you need to reprocess specific items:

1. Extract barcodes from the sorting spreadsheet or workflow JSON
2. Create a new subfolder with just those images
3. Run the workflow on that smaller batch
4. Compare results to original processing

### Tracking corrections:

When catalogers correct AI suggestions:
- Note the barcode and original vs. correct OCLC number
- Review the AI's reasoning in the workflow JSON
- Document why the AI made that choice
- Use this information to refine future processing

---

## BATCH RECOVERY

If batch processing is interrupted (power outage, network issues, computer shutdown), you can recover:

### List active batches:
```bash
python ai-music-workflow/batch_recovery.py list
```

### Resume an interrupted batch:
```bash
python ai-music-workflow/batch_recovery.py resume batch_abc123xyz456
```

### Clean up completed batches:
```bash
python ai-music-workflow/batch_recovery.py cleanup
```

**Notes:**
- Batch IDs are automatically saved to `~/.ai-music-batch-state/` when submitted
- Batches continue processing on OpenAI's servers even if your script stops
- You can resume batches anytime within 24 hours

---

## ALMA BATCH UPLOAD (SANDBOX ONLY)

The Alma batch upload scripts create bibliographic, holding, and item records in Alma Sandbox using OCLC numbers from the workflow.

### Scripts:
- **CD workflow**: `ai-music-workflow/cd-processing/alma_batch_upload_cd.py`
- **LP workflow**: `ai-music-workflow/lp-processing/alma_batch_upload_script_lp.py`

### Required Environment Variables:
```bash
ALMA_SANDBOX_API_KEY    # Your Alma sandbox API key
OCLC_CLIENT_ID          # OCLC API credentials
OCLC_SECRET             # OCLC API credentials
ALMA_LIBRARY_CODE       # Your library code
ALMA_LOCATION_CODE      # Shelving location code
ALMA_CD_ITEM_POLICY     # Item policy for CDs
ALMA_LP_ITEM_POLICY     # Item policy for LPs
ALMA_CATALOGING_INSTITUTION  # Cataloging institution code
```

### Optional Environment Variables:
```bash
ALMA_REGION             # Default: api-na (North America)
ALMA_INTERNAL_NOTE_2    # Default: "AI-assisted cataloging"
```

### Usage:
```bash
python path/to/alma_batch_upload_cd.py path/to/batch-upload-file.txt [options]
```

### Options:
- `--delimiter '|'` - Override default delimiter
- `--yes` - Skip confirmation prompt (for non-interactive runs)
- `--report` - Print summary only, no imports
- `--restrict-dir /path` - Limit inputs to specific directory

### What it does:
1. Fetches WorldCat records using OCLC numbers
2. Builds MARCXML and imports new bibs to Alma
3. Creates holdings at your configured library/location
4. Creates item records with appropriate material type
5. Skips titles already in your Alma instance
6. Writes a CSV of created IDs (MMS, holding, item)

**Important**: These scripts are for sandbox experimentation only. Test thoroughly before considering production use.

---

## MONITORING RECOMMENDATIONS

### Per Batch:
- Check `error-log-[date].json` for serious issues
- Review confidence score distribution
- Verify OCLC API success rate
- Scan for unusual patterns

### Monthly:
- Analyze trends in AI performance
- Review cataloger correction rates
- Track processing efficiency
- Document lessons learned

### Quarterly:
- Comprehensive review of all batches
- Calculate overall success rates
- Identify materials needing special handling
- Report on workflow effectiveness

---

## WORKFLOW PHILOSOPHY

This system is designed to:
- **Accelerate** routine cataloging tasks
- **Flag uncertainty** rather than making questionable decisions
- **Create audit trails** for all processing steps
- **Support continuous improvement** through comprehensive data

**Important**: The goal is to assist catalogers, not replace them. When AI is uncertain, it should defer to human expertise.

---

## GETTING HELP

### For technical issues:
- Check `error-log-[date].json` first
- Review `processing-metrics-[date].json` for patterns
- Consult workflow JSON for specific record details

### For workflow questions:
- Review this guide and the Cataloger Guide
- Consult with experienced workflow users
- Document issues for future reference

### For significant problems:
- Gather relevant log files and examples
- Note batch details (date, size, material type)
- Contact workflow administrators with documentation