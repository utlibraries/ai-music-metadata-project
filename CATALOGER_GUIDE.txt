# AI MUSIC WORKFLOW - CATALOGER GUIDE

## How to use the files created by the AI music cataloging workflow to review results and sort physical items.

---

## OVERVIEW

This AI workflow processes CD/LP images by:
1. Extracting metadata from images using AI
2. Searching OCLC for matching records
3. Using AI to analyze matches and assign confidence scores
4. Automatically checking track listings and publication dates
5. Downgrading results with mismatches
6. Creating final outputs to simplify organization and cataloging

The workflow is an effective cataloging tool but is **not meant to replace professional judgment**. Always test thoroughly and maintain quality controls.

---

## STEPS AFTER RUNNING AUTOMATED WORKFLOW

1. **Sort items** using the sorting spreadsheet
2. **Track review progress** using the cataloger review spreadsheet - reference the low confidence review text file in this process
3. **Use MARC text file** to help with original cataloging where needed
4. **Upload verified results** - high confidence and cataloger-verified results to your Library Services Platform
5. **(Optional) Use HTML interface** - if generated, review matches with images side-by-side

---

## KEY FILES CREATED

All output files are organized in three subfolders within your results folder:

### **`deliverables/` folder** - Files for cataloging work

1. **SORTING SPREADSHEET**: `sorting-spreadsheet-[date].xlsx`
   - All items categorized into groups (High Confidence, Held by UT Libraries, Low Confidence, Duplicates)
   - Use this to physically organize your materials

2. **BATCH UPLOAD FILE**: `batch-upload-alma-[cd/lp]-[timestamp].txt`
   - Simplified, de-duplicated, pipe-delimited file for high-confidence matches
   - Format: `OCLC_NUMBER|BARCODE|TITLE`
   - Ready to upload to your Library Services Platform

3. **CATALOGER REVIEW SPREADSHEET**: `tracking-spreadsheet-catalogers-[date].xlsx`
   - Tracking spreadsheet for reviewing low-confidence matches
   - Yellow highlighting indicates items needing attention
   - Once you enter an OCLC number, highlighting disappears
   - Contains dropdown menu and notes for each item

4. **LOW CONFIDENCE REVIEW SPREADSHEET**: `low-confidence-matches-review-[date].xlsx`
   - Detailed text log with:
     - AI-generated metadata
     - AI-suggested OCLC record
     - Other potential matches found
     - Full OCLC record details

5. **MARC SPREADSHEET**: `marc-formatted-low-confidence-matches-[date].xlsx`
   - MARC-formatted records based on AI-extracted metadata
   - Starting point for original cataloging
   - Pared down to basics with only visible/available data

6. **DECISIONS HISTORY**: `decisions-history.xlsx`
   - Audit log & **source of truth** for all cataloger decisions (per barcode)
   - Can re-run. Contains two sheets: **Current Decisions** (latest) and **Decision History** (all)
   - Populated by **Step 7** from the CSV; **don’t hand-edit**
   - Drives updates to sorting, batch upload, and low-confidence files

### **`guides/` folder** - Documentation

- `CATALOGER_GUIDE.txt` - This guide, intended to help catalogers effectively use results
- `TECHNICAL_GUIDE.txt` - Technical documentation for troubleshooting

### **`data/` folder** - Workflow data files

- Full workflow JSON and Excel files (for advanced troubleshooting)

### **`images/` folder** - Only if HTML interface generated

- Copies of all processed images (for portability of HTML review)

---

## USING THE CATALOGER REVIEW SPREADSHEET

The `tracking-spreadsheet-catalogers-[date].xlsx` file is your primary tool for handling low-confidence matches.

### COLUMNS:
- **Barcode**: Physical item identifier
- **Date AI Processed**: When the workflow ran
- **AI-Suggested OCLC Number**: AI's best guess from OCLC results (may be blank)
- **Title**: Title from OCLC record (or "No OCLC match found")
- **Date Cataloger Checked**: Fill in when you review
- **Status**: Dropdown with three options (see below)
- **Correct OCLC Number**: Auto-fills if AI suggestion approved, or manually enter
- **Notes**: Your comments and observations

### STATUS DROPDOWN OPTIONS:

1. **"Approved"** - AI suggestion is correct
   - Correct OCLC Number auto-fills with AI suggestion
   - Row highlighting disappears automatically

2. **"Rejected - Different OCLC"** - AI found wrong record
   - Manually enter correct OCLC number in Correct OCLC column
   - Row highlighting disappears when OCLC number entered

3. **"Rejected - Needs Original Cataloging"** - No OCLC record exists
   - Leave Correct OCLC Number blank
   - Use MARC format file as cataloging starting point
   - Once you create an OCLC number, you may fill it in (highlighting will disappear)

---

## SORTING PHYSICAL ITEMS

The `sorting-spreadsheet-[date].xlsx` helps you organize physical CDs/LPs into these groups:

### 1. **Alma Batch Upload (High Confidence)**
- Simple and deduplicated, only high confidence results
- Intended for batch uploads to Library Services Platforms
- Physical items can go directly to appropriate collection

### 2. **Held by UT Libraries (IXA)**
- Items already in catalog (according to OCLC Search API)
- **Action needed**:
  - Verify these items are indeed duplicates
  - Check that existing items don't have condition issues
  - May need withdrawal processing

### 3. **Cataloger Review (Low Confidence)**
- Use `tracking-spreadsheet-catalogers-[date].xlsx` for decisions
- Keep items accessible for hands-on verification
- Reference the low confidence review text file for detailed information
- Sort based on cataloger review outcomes

### 4. **Duplicates**
- Multiple copies of same title identified in this batch
- **Action needed**:
  - Check condition
  - Make retention decisions
  - May keep best copy, withdraw others

---

## OPTIONAL: HTML REVIEW INTERFACE

If you chose to generate the HTML interface (Step 6), you'll find these files in your main results folder:

- **`review-index-[date].html`** - Start here
- **`review-page-[#]-[date].html`** - Individual review pages

### How to use the HTML interface:

1. **Download the entire results folder** to your local computer
2. **Unzip** if compressed
3. **Double-click** `review-index-[date].html` to open in your web browser
4. Review items with images displayed alongside OCLC records
5. Make decisions and add notes directly in the interface
6. **Export decisions to CSV** when done

### Important notes about HTML:
- Runs entirely on your local machine (no internet connection needed for viewing)
- Your decisions are stored in your browser's local storage only
- **You must export to CSV to save your work permanently**
- Not recommended for batches over 500 records (folder size becomes very large)
- Best with JPEG images (smaller file sizes)


## PROCESSING CATALOGER DECISIONS (STEP 7)

After you've reviewed low-confidence matches and made your decisions, you need to process those decisions to update the workflow deliverable files.

### EXPORTING DECISIONS FROM HTML INTERFACE

1. **Make your decisions** on review pages
2. **Export to CSV** using the "Export All Decisions to CSV" button on the index page
3. **Save the CSV file** to the **results folder**


### RUNNING STEP 7 TO APPLY DECISIONS

Once your cataloger decision CSV is saved in the results folder, you can either request that the administrator of the pipeline run step 7 on your decision CSV or, if you have access to the script, you can:

1. **Run Step 7** of the workflow (apply cataloger decisions script)
2. **Provide the CSV path** when prompted
3. **Provide the results folder path** when prompted

### WHAT STEP 7 DOES

Step 7 processes your cataloger decisions and updates all deliverable files:

- **Sorting spreadsheet** - Updates status, OCLC numbers, and confidence scores
- **Batch upload file** - Adds newly approved items, removes rejected items
- **Low confidence files** - Removes approved items, keeps items still needing review
- **Tracking spreadsheet** - Updates review dates and status
- **Decisions history** - Creates permanent audit trail of all decisions

### IMPORTANT NOTES

- **Original files are backed up** - Your original outputs are copied to `original-outputs/` folder before any changes
- **Decision history is tracked** - All decisions are versioned (v1, v2, v3, etc.) in `decisions-history.xlsx`
- **You can run Step 7 multiple times** - As you complete more reviews, re-run Step 7 to integrate new decisions
- **Confidence scores update automatically**

### AFTER STEP 7 COMPLETES

Your updated files in the `deliverables/` folder are now ready:

1. **Updated batch upload file** - Contains all verified high-confidence matches
2. **Updated sorting spreadsheet** - Reflects all cataloger decisions
3. **Updated tracking spreadsheet** - Shows current review status
4. **Decisions history** - Complete audit trail of all changes

You can now proceed with uploading verified records to your Library Services Platform with the Alma Batch Upload script.
---

## TROUBLESHOOTING

### For questions about specific OCLC records:
- Use the low confidence review text file
- Check "Other Potential Matches" section for alternatives
- Verify against physical CD/LP

### If OCLC numbers seem wrong:
- The workflow uses multiple verification layers and low confidence items are flagged for human review
- However, trust your professional judgment over AI suggestions

---

## QUALITY CONTROL

The AI workflow provides multiple verification layers.

**However**: AI is a tool to accelerate cataloging, not to replace professional judgment. When in doubt, follow standard cataloging practices and institutional policies.

---

## WORKFLOW SUMMARY

```
Images → Metadata Extraction → OCLC Search → AI Analysis → 
Verification → Classification → Output Files → Optional HTML → Optional Deliverable Updates → Optional Batch Uploads
```

